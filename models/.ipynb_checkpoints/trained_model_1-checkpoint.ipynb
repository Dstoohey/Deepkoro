{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from string import punctuation\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "vocab_size = 39  #len(int2char)\n",
    "char2int = pickle.load(open(f\"char2int.pickle\", \"rb\"))\n",
    "int2char = pickle.load(open(f\"int2char.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(256, input_shape=(sequence_length, vocab_size), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(256),\n",
    "    Dense(vocab_size, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(f\"resultsalltexts.txt-100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating text: 100%|██████████| 200/200 [00:09<00:00, 22.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: in the\n",
      "Generated text:\n",
      "\n",
      "son and\n",
      "the son\n",
      "\n",
      "3112 and\n",
      "the son\n",
      "\n",
      "3112 and\n",
      "the son\n",
      "\n",
      "3112 and\n",
      "the son\n",
      "\n",
      "3112 and\n",
      "the son\n",
      "\n",
      "3112 and\n",
      "the son\n",
      "\n",
      "3112 and\n",
      "the son\n",
      "\n",
      "3112 and\n",
      "the son\n",
      "\n",
      "3112 and\n",
      "the son\n",
      "\n",
      "3112 and\n",
      "the son\n",
      "\n",
      "3112 and\n",
      "the son\n",
      "\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#model.load_weights(f\"resultsalltexts.txt-100.h5\")\n",
    "# specify the feed to first characters to generate\n",
    "seed = \"in the\"\n",
    "s = seed\n",
    "n_chars = 200\n",
    "# generate 180 characters\n",
    "generated = \"\"\n",
    "for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
    "    # make the input sequence\n",
    "    X = np.zeros((1, sequence_length, vocab_size))\n",
    "    for t, char in enumerate(seed):\n",
    "        X[0, (sequence_length - len(seed)) + t, char2int[char]] = 1\n",
    "    # predict the next character\n",
    "    predicted = model.predict(X, verbose=0)[0]\n",
    "    # converting the vector to an integer\n",
    "    next_index = np.argmax(predicted)\n",
    "    # converting the integer to a character\n",
    "    next_char = int2char[next_index]\n",
    "    # add the character to results\n",
    "    generated += next_char\n",
    "    # shift seed and the predicted character\n",
    "    seed = seed[1:] + next_char\n",
    "\n",
    "print(\"Seed:\", s)\n",
    "print(\"Generated text:\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #model.load_weights(f\"resultsalltexts.txt-100.h5\")\n",
    "# # specify the feed to first characters to generate\n",
    "# seed = i am the Lord thy God thou shalt not have any strange gods before me\n",
    "# s = seed\n",
    "# n_chars = 200\n",
    "# # generate 180 characters\n",
    "# generated = \"\"\n",
    "# for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
    "#     # make the input sequence\n",
    "#     X = np.zeros((1, sequence_length, vocab_size))\n",
    "#     for t, char in enumerate(seed):\n",
    "#         X[0, (sequence_length - len(seed)) + t, char2int[char]] = 1\n",
    "#     # predict the next character\n",
    "#     predicted = model.predict(X, verbose=0)[0]\n",
    "#     # converting the vector to an integer\n",
    "#     next_index = np.argmax(predicted)\n",
    "#     # converting the integer to a character\n",
    "#     next_char = int2char[next_index]\n",
    "#     # add the character to results\n",
    "#     generated += next_char\n",
    "#     # shift seed and the predicted character\n",
    "#     seed = seed[1:] + next_char\n",
    "\n",
    "# print(\"Seed:\", s)\n",
    "# print(\"Generated text:\")\n",
    "# print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating text: 100%|██████████| 200/200 [00:08<00:00, 22.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: who hath taught the use of the pen\n",
      "Generated text:\n",
      "ishath\n",
      "\n",
      "3112 and he said unto him he said the\n",
      "lord hath been sent down to the chief\n",
      "of the chief of the chief priests of\n",
      "the chief captivity of the chief priest\n",
      "\n",
      "3112 and the chief captain of the chie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#model.load_weights(f\"resultsalltexts.txt-100.h5\")\n",
    "# specify the feed to first characters to generate\n",
    "seed = \"who hath taught the use of the pen\" \n",
    "s = seed\n",
    "n_chars = 200\n",
    "# generate 180 characters\n",
    "generated = \"\"\n",
    "for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
    "    # make the input sequence\n",
    "    X = np.zeros((1, sequence_length, vocab_size))\n",
    "    for t, char in enumerate(seed):\n",
    "        X[0, (sequence_length - len(seed)) + t, char2int[char]] = 1\n",
    "    # predict the next character\n",
    "    predicted = model.predict(X, verbose=0)[0]\n",
    "    # converting the vector to an integer\n",
    "    next_index = np.argmax(predicted)\n",
    "    # converting the integer to a character\n",
    "    next_char = int2char[next_index]\n",
    "    # add the character to results\n",
    "    generated += next_char\n",
    "    # shift seed and the predicted character\n",
    "    seed = seed[1:] + next_char\n",
    "\n",
    "print(\"Seed:\", s)\n",
    "print(\"Generated text:\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating text: 100%|██████████| 150/150 [00:06<00:00, 24.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: excellent presentation\n",
      "Generated text:\n",
      "\n",
      "\n",
      "3112 and the chief captain\n",
      "of the chief priests and\n",
      "the sons of her son and\n",
      "they shall be the sons\n",
      "of his brethren and the\n",
      "chief captain of the chie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#model.load_weights(f\"resultsalltexts.txt-100.h5\")\n",
    "# specify the feed to first characters to generate\n",
    "seed = \"excellent presentation\" \n",
    "s = seed\n",
    "n_chars = 150\n",
    "# generate 180 characters\n",
    "generated = \"\"\n",
    "for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
    "    # make the input sequence\n",
    "    X = np.zeros((1, sequence_length, vocab_size))\n",
    "    for t, char in enumerate(seed):\n",
    "        X[0, (sequence_length - len(seed)) + t, char2int[char]] = 1\n",
    "    # predict the next character\n",
    "    predicted = model.predict(X, verbose=0)[0]\n",
    "    # converting the vector to an integer\n",
    "    next_index = np.argmax(predicted)\n",
    "    # converting the integer to a character\n",
    "    next_char = int2char[next_index]\n",
    "    # add the character to results\n",
    "    generated += next_char\n",
    "    # shift seed and the predicted character\n",
    "    seed = seed[1:] + next_char\n",
    "\n",
    "print(\"Seed:\", s)\n",
    "print(\"Generated text:\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
